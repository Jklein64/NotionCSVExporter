Name,Accuracy,Created,Date,Formatted,Hours,Minutes,Comments
Attempt to Formulate Problem,ðŸ’ª Confident,"July 26, 2021 10:25 PM","July 26, 2021",2.91 hour(s),2.91,175,"Researched the different types of optimization problems and found various slideshow presentations from a good majority of the colleges I was thinking of applying to (who knew that Wisconsin-Madison has Stephen J. Wright, an absolute powerhouse of a computer science professor?).  See [Overview of Optimization](https://www.notion.so/Overview-of-Optimization-c3ad7d3019b440d5b48502b23b389b48) for more information and also some links.

---

I then decided to try hacking on my definitions to the one that I found in the paper *An Improved Geometric Approach for Palette-based Image Decomposition and Recoloring*, replacing variable names, definitions, and explanations as I felt necessary.  I think it turned out quite nicely (and Yotam seems impressed!).

---

# Formulation

Our goal is to generate a polyhedron $\mathbf P$ that minimizes the following energy function $F(\mathbf P)$ where $REC(\cdot)$ is the reconstruction loss and $REP(\cdot)$ is the representative loss.Â  $\lambda$ and $\mu$ are parameters that control the contribution of each loss function to the energy function and the radius which selects neighboring points respectively.Â  The goal is to find the polyhedron that minimizes both of these losses as would be the most representative of the pixels in the image while also having the smallest reconstruction error.

$$\argmin_{\mathbf P} F(\mathbf P),\ F(\mathbf P) = \lambda \cdot REC(\mathbf P, \mathbf I) + REP(\mathbf V, \mathbf I, \mu)$$

The reconstruction loss $REC(\cdot)$ is a function of the polyhedron $\mathbf P$ and also $\mathbf I$, the set of all of the pixel values in the image.Â  $\mathbf i$ is an individual pixel in the image, and $\mathbf {i_p}$ is the closest point to $\mathbf i$ on the polyhedron if it is outside of the polyhedron, and is otherwise equivalent to $\mathbf i$.  The reconstruction loss is the average number of pixels that would not be recreated perfectly (meaning they lie outside $\mathbf P$) after decomposing the image $\mathbf I$ into the palette colors, weighed by the smallest distance of that pixel to $\mathbf P$.

$$REC(\mathbf P, \mathbf I) = \frac{1}{|{\mathbf I}|} \sum_{\mathbf i \in \mathbf I} || \mathbf i - \mathbf {i_p} ||$$

The representative loss $REP(\cdot)$ is a function of the color palette $\mathbf V$ (analogous to the set of vertices of the polyhedron $\mathbf P$) and also $\mathbf H$, the set of vertices of the convex hull of all of the points in $\mathbf I$ with no simplification.Â  Representative loss is the average distance between any given vertex of $\mathbf P$ and all of the vertices of $\mathbf H$ within a radius of size $\mu$ from the given vertex (if there are no vertices within this radius, then use the nearest vertex of $\mathbf H$ regardless of distance).Â  Due to the definition of a convex hull and the fact that $\mathbf P$ is a simplified form of $\mathbf H$, all of the vertices of $\mathbf P$ are initially guaranteed to not be within $\mathbf H$.

$$REP(\mathbf V, \mathbf H, \mu) =

\frac{1}{|\mathbf V|}

\sum_{\mathbf v \in \mathbf V}

  \Bigg\lvert \Bigg\lvert 

  \mathbf v -

  \frac 1 {|\mathbf{N_{\mathbf v}}|}

  \sum_{\mathbf n \in     
  \mathbf{N_{\mathbf v}}}

    \mathbf n

  \Bigg\rvert \Bigg\rvert$$

$$\begin{aligned}
\text{where}\ 

\mathbf N_{\mathbf v} &= \{ 
  \mathbf h 
  \mid
  \mathbf h \in \mathbf H
  \text{ and }
  ||\mathbf v - \mathbf h|| \le\mu
\}

\\
&= \{
 \argmin_{\mathbf h}
 ||\mathbf v - \mathbf h||
\}

\ \text{if $\mathbf N_{\mathbf v}$ would be empty}
\end{aligned}$$"
Explain my idea,ðŸ¤ž Mostly guessing,"July 25, 2021 6:25 PM","July 25, 2021",1.66 hour(s),1.66,100,"Spent a long time trying to figure out how to load the `fastLayerDecomposition` server again, since I wanted to get an example to help explain what my algorithm would do.  I had saved the code (and ran it through `autopep8` for formatting) so that I could read through it and try to find and intercept where the hull was being simplified (see yesterday's or the day before's notes).  It turns out that saving it for some reason led to weird python module import issues.  I wish python modules were like lua's `require()`, which literally just runs the file.

---

Once I got the `fastLayerDecomposition` demo up and running, I uploaded `turquoise.png` and took screenshots of the simplified convex hull and image decomposition before and after moving the blue vertex closer to the points, and then annotated them (see below).

![Explain%20my%20idea%2021b3b4262b72439b919dbe00e587509d/annotated.png](Explain%20my%20idea%2021b3b4262b72439b919dbe00e587509d/annotated.png)

[annotated.afphoto](Explain%20my%20idea%2021b3b4262b72439b919dbe00e587509d/annotated.afphoto)

> [Me] I guess this is similar to moving toward neighboring points, except we don't have to calculate nearly as many times (or estimate the points by taking a random selection like I think *An Improved Geometric Approach for Palette-based Image Decomposition and Recoloring* did) since $N$ for neighbors would be the vertices of the convex hull instead of every single point. We could also try simplifying the original hull, but just not as much as the one that we're trying to correct.

> [Yotam] If you can express your desire as a continuous function, we can run a numerical continuous optimization algorithm on it (even something as simple as gradient descent). It should continuously deform the vertices of a polyhedron."
Read some sample abstracts,ðŸ¤” Pretty Sure,"July 25, 2021 2:11 AM","July 24, 2021",0.41 hour(s),0.41,25,"Read some sample abstracts, including a whole webpage's worth of samples that were submitted to talks or similar.  The framework that I found and put into the [](https://www.notion.so/728f6b38997b441f9edda59324ccf581) database (see [How to Write a CS Paper](https://www.notion.so/How-to-Write-a-CS-Paper-05b4f4ac8d5146f4b1711b9fc44c86a8)).

[Computer Graphics Abstracts](https://course.ccs.neu.edu/csg140/abstracts/abstracts2006.html)

In general, I think I have a feel for how computer science abstracts look.  The thing that's preventing me from completing my own is that I don't have any work to show for all of my research.  There is no solution, there is no proposal or data or way to prove that I have iterated upon the state of the art.  oof"
Read Through Yotam's Code,ðŸ¤” Pretty Sure,"July 24, 2021 4:52 AM","July 23, 2021",1.5 hour(s),1.5,90,"Read through the code in the `fastLayerDecomposition` repository which contains the client and server that actually runs the code from the paper.  The code is extremely extensive (especially the threejs part, which for some reason was shoved into a >1000-line file).

I was looking through the code to see if there was an easy point to insert my theory of an optimization algorithm.  I read through the areas that handled the points, hull, and palette, including the callbacks in the server and the 60-bajillion helper methods in the js file (thank god for VSCode's `peek > References` feature), but didn't see an easy place to put it.

I think the best idea would be to implement my algorithm in my own server.  Just make the lines thicker and have some way to differentiate between the simplified and unsimplified hulls (as well as a way to simplify them... maybe steal that from `fastLayerDecomposition`?).

## My Algorithm

> What if we used the unsimplified convex hull as a sort of target for the simplified one? Starting with the vertex of the simplified hull that is farthest from the unsimplified one and repeating, shift the vertex closer to the closest match to a corresponding vertex of the unsimplified hull (or farther away if needed for the optimization problem, which I realize is why that paper went from [-.5, 1]) but in a way that ensures the simplified hull is only excluding some ðœ– points at most. Isn't a simplified polyhedron that resembles the unsimplified hull better than a simplification that is still a convex hull but isn't as tightly fit to the original data?

### TODO

- [ ]  Formulate as a formal optimization problem (what is an ""optimization problem""?)
- [ ]  Write the code to calculate the convex hulls (maybe do everything in threejs, since `[new THREE.ConvexHull().setFromPoints()](https://threejs.org/docs/?q=half#examples/en/math/convexhull/ConvexHull.setFromPoints)` looks like it might actually work pretty well)
    - threejs does weird things with half-edges instead of letting faces be defined by `points[hull.simplices]` though...
- [ ]  Write the code to run the optimization algorithm.  Maybe take inspiration from the first paper Yotam had me read (*An Improved Geometric Approach for Palette-based Image Decomposition and Recoloring*)?
- [ ]  Optional: create a screenshot feature and then save a screenshot every step or so and then reconstruct them into a video."
Color Upload and Selection,ðŸ¤” Pretty Sure,"July 22, 2021 5:57 AM","July 21, 2021",9.25 hour(s),9.25,555,"Spent more time putting the renderer together with a python script.  Modified the script to calculate the k-means with respect to r, g, b, x, and y, and then send the centroids over to the server.  Created an API for changing the color of the point cloud without affecting the actual positions, and also created a selection type called ""same color"" which will make a selection as usual and then add all of the points that share a color with any of the points in the selection.  This works really well when combined with the ability to upload points, as clusters from the k-means can be uploaded as colors."
Lasso Selection and New Idea,ðŸ’ª Confident,"July 21, 2021 1:34 AM","July 20, 2021",4.16 hour(s),4.16,250,"I spent the time working on the renderer again whoops.  And I didn't even get the points thing working yet.  That's for the next time I did get back in.  I did, however, make it much easier to select points by switching from a box selection to a lasso selection.  In order to get the lasso selection to work, I needed to learn about point-in-polygon algorithms and winding numbers.  The idea behind the algorithm I ended up using is this: 

> let $\vec a$ and $\vec b$ be consecutive vertices of polygon $P$ (the lasso), point $\vec p$ be the query point, and $included$ be whether or not $\vec p$ is inside of $P$.  For every possible pair of $\vec a$ and $\vec b$, if $\vec {p_y}$ lies within $\vec {a_y}$ and $\vec {b_y}$ and $\vec p$ is to the left when looking at $\vec b$ from $\vec a$, then invert $included$.  The final value of $included$ is whether or not $\vec p$ is inside of $P$.

---

I also made an interesting observation.  As I didn't have easy access to the original image, I took a screenshot of a small thumbnail of one of the images used in the RGBXY decomposition paper.  When I put it into the renderer, I noticed that there were parts of the image that were more sparse (less dense) relative to the main clumps.  Selecting these (which was only possible with the new lasso and selection mode tools) revealed that they were generally pretty insignificant.

![Lasso%20Selection%20and%20New%20Idea%20f88a3c196d2f40d49487d9dbdbe387be/Screen_Shot_2021-07-20_at_4.54.26_PM.png](Lasso%20Selection%20and%20New%20Idea%20f88a3c196d2f40d49487d9dbdbe387be/Screen_Shot_2021-07-20_at_4.54.26_PM.png)

There's a pretty significant sparse area slightly down and left of pure white.

![Lasso%20Selection%20and%20New%20Idea%20f88a3c196d2f40d49487d9dbdbe387be/thoughts.png](Lasso%20Selection%20and%20New%20Idea%20f88a3c196d2f40d49487d9dbdbe387be/thoughts.png)

The green is what was selected, represented in both the point cloud and in the image (I actually like this view for the image; maybe I should switch it to default to the inverted color instead of white...).  Despite the large area that the selection appears to cover, the pixels the selection represents are scant and generally insignificant.  This strategy could be used to attempt to remove artifacts from images, and the density might be a good estimate of importance relative to the image."
Next Steps,ðŸ¤” Pretty Sure,"July 20, 2021 6:45 AM","July 19, 2021",3.83 hour(s),3.83,230,"Got started writing some python again.  Working with numpy arrays isn't that scary as long as I write a comment whenever an array changes shape (and also comments describing the shapes of parameters and the like).  At first, I tried to replace the k-means clustering with delaunay tessellation, but that wasn't working.  It was creating *more* clusters than there were points, so something was off (I asked Yotam if he knew).

---

Generalized the server post request code so it will accept a post request to `/:endpoint` and send `endpoint` as the `type` in the Server Sent Event JSON object.  This is in anticipation of wanting to add a lot more endpoints as I see fit, such as for drawing meshes for convex hulls or plotting clusters with specific colors (I currently want to do the latter)."
Work on Renderer,ðŸ’ª Confident,"July 19, 2021 1:12 AM","July 18, 2021",10 hour(s),10,600,"Wrapped up loose ends of the renderer, handle state properly, refactor, etc.  Enabled the ability to upload images (from base64, which you could get to programatically) and convex hulls from a jupyter notebook to be displayed in the renderer, so now I can ditch previewing things with slow and laggy matplotlib :)

---

Learned a lot about Server Sent Events, which are an overlay to the HTTP standard.  By flipping a couple of headers and never ending the request (and also using a special API on the frontend called `EventSource`), the client can always be up to date with the server without forcing the server to keep track of every single one of its connected clients manually.  It meant for a lot less code on my part, but wasn't nearly as popular in tutorials as websockets and didn't have any wrappers or similar."
Attend End of SGP,ðŸ’ª Confident,"July 18, 2021 7:32 AM","July 14, 2021",2 hour(s),2,120,Yotam invited me to join for the last couple of presentations at SGP (and also join their discord group).
Research Algorithmic Complexity,ðŸ¤ž Mostly guessing,"July 14, 2021 5:10 AM","July 13, 2021",3.83 hour(s),3.83,230,"I watched a MIT OpenCourseWare YouTube video on algorithmic complexity, read some wikipedia articles, and skimmed a chapter or two from a textbook.  I still don't quite understand how this might apply to the fullest extent, but I think I now know enough to be able to understand Yotam when he dismisses ideas for being ""NP-hard"".

---

[16. Complexity: P, NP, NP-completeness, Reductions](https://www.youtube.com/watch?v=eHZifpgyH_4)

[](https://notendur.hi.is/mae46/Haskolinn/5.%20misseri%20-%20Haust%202018/Formleg%20ma%CC%81l%20og%20reiknanleiki/Introduction%20to%20the%20theory%20of%20computation_third%20edition%20-%20Michael%20Sipser.pdf)

[Reduction (complexity) - Wikipedia](https://en.wikipedia.org/wiki/Reduction_(complexity))

[P versus NP problem - Wikipedia](https://en.wikipedia.org/wiki/P_versus_NP_problem)"
Touch up Visualization,ðŸ¤” Pretty Sure,"July 14, 2021 5:07 AM","July 13, 2021",2 hour(s),2,120,"- Refactor some code
- Try to catch any bugs that might show up
- Adjust README
- Publish to public GitHub repository
    - [ ]  Create general README
    - [ ]  Link to Jupyter notebook (if applicable)
    - [ ]  Host HTML file on GitHub pages so that it doesn't need to be downloaded"
Complete Visualization!,ðŸ’ª Confident,"July 13, 2021 6:34 AM","July 12, 2021",4.75 hour(s),4.75,285,"Work on and complete the visualization software.  Now I can actually see which of the parts of the RGB-space pixel point thingies correspond to which parts of the image, which will hopefully help me develop an intuition for it.

---

Next step could be to link it to the jupyter notebook.  Not sure how helpful that would be though... would need to investigate further."
Complete Box Selection!,ðŸ’ª Confident,"July 9, 2021 11:46 PM","July 9, 2021",4.25 hour(s),4.25,255,"Completed the box selection ability!  Can now select with the mouse while holding shift and it will put all of the selected points into a list (and also color them white).  The next step is to put the pixels from an image into the cube (instead of a random distribution of particles), store each $(x, y)$ image coordinate along with the pixel colors and locations in 3D space, and then match these up with the selection to be able to select parts of the image from the point cloud."
Work On Visualization Tool,ðŸ’ª Confident,"July 9, 2021 7:58 AM","July 8, 2021",11 hour(s),11,660,"Learned a significant portion of THREE.js, which is really powerful and for some reason feels a lot less painful than python-style libraries.  Â¯\_(ãƒ„)_/Â¯. It turns out that vector projection gets really messy when it's difficult to define coordinate systems on planes...

Worked for a while at the beginning trying to create a keyboard-controlled system, but that didn't work well because I had to rotate the points instead of the camera (the math was too complicated; I almost figured it out by using spherical coordinates but $\phi$ (phi) would only go from $[0, \pi)$ and I needed it to wrap around, which my head could not wrap around (bad pun).  Ended up using not `OrbitalController` but `TrackballControls` which let me rotate over the top.

Worked on the selection mechanism for *a long time*.  Projecting from signed screen space into 3D is difficult (even when the origins line up), but the most difficult part is figuring out which of the points are actually inside of the box.  I can draw a box (the selection box) on a plane normal to the camera's looking vector and then project all of the points to this plane, but I can't easily shift to analyzing the points/box in two dimensions, which would be *sooooo* much easier.  I'm currently trying with some weird `vector.project(camera)` trickery, but the closest I got was selecting portions that weren't remotely related for seemingly no reason.

(almost forgot but I tried to screw around with vscode native notebooks some since I noticed that they aren't using GitHub-flavored markdown, but couldn't figure out how to switch it)"
Call With Yotam,ðŸ’ª Confident,"July 8, 2021 4:07 AM","July 7, 2021",2 hour(s),2,120,"Very productive call.  We discussed the progress I had made with the k-means strategy and other similar attempts to isolate the outliers.  Then, I had an *a-ha* moment and realized that my definition of an outlier I came up with a couple of weeks ago was actually really close to being useful: it just needed each of its two parts to be quantifiable.

See meeting notes for more information."
Implement Yotam's Algorithm,ðŸ’ª Confident,"July 7, 2021 2:22 AM","July 6, 2021",7.5 hour(s),7.5,450,"Worked on reading an image using PIL and converting it into a numpy `ndarray` and doing math with that.  Then messed with scipy and figured out how to find the vertices of the convex hull of a set of points and then draw them using matplotlib

---

Switched to using a Jupyter notebook so that I didn't have to run kmeans and regenerate k convex hulls every time (it only takes 15s or so, but that's still somewhat annoying).  Spent a long time figuring out how to graph the results, but eventually ended with this:

![Implement%20Yotam's%20Algorithm%203a8561f3be46400abcf135044be12a34/summary.png](Implement%20Yotam's%20Algorithm%203a8561f3be46400abcf135044be12a34/summary.png)

[summary.afphoto](Implement%20Yotam's%20Algorithm%203a8561f3be46400abcf135044be12a34/summary.afphoto)

Food for thought: are we more likely to find an outlier near the extremes of RGB space?"
Tinker With Setup,ðŸ¤” Pretty Sure,"July 4, 2021 2:11 PM","July 4, 2021",1.5 hour(s),1.5,90,"Add icons to the notion and reorganize the ASSIP folder.  Also modified the note generator script to work in whichever directory it's in so that I could just copy-paste it into another one for the Yotam meetings.  Now I won't have to change the script when I move the entire folder.  Installed gnu `grep` in the process, which is much better since it has the `-P` flag."
Research 3D Outliers,ðŸ¤” Pretty Sure,"July 2, 2021 6:31 AM","July 1, 2021",1.08 hour(s),1.08,65,"Found a couple of good resources on finding multivariate outliers. Itâ€™s a tricky problem, and some of the solutions donâ€™t generalize to $n$ dimensions (only to like 3, whereas we would like 5).  Thereâ€™s also a whole bunch of wacky stats vocab (ugh why did this have to become a stats problem...), such as â€œMahalanobis distanceâ€

[yzhao062/anomaly-detection-resources](https://github.com/yzhao062/anomaly-detection-resources#31-multivariate-data)

List of algorithms that can be used to find the outliers [shared with Yotam]

[](https://people.csail.mit.edu/changil/assets/point-cloud-noise-removal-3dv-2016-wolff-et-al.pdf)

Paper on removing outliers from point clouds (though intended for mesh generation instead of RGB stuff) [shared with Yotam]

[](https://www.researchgate.net/profile/Mohammad-Awrangjeb/publication/337006587_An_unsupervised_outlier_detection_method_for_3D_point_cloud_data/links/5dbfd04c4585151435e5210d/An-unsupervised-outlier-detection-method-for-3D-point-cloud-data.pdf?origin=publication_detail)

Similar to above, but paid closer attention to how many real points were being misclassified, since that can lead to problems. Data set was small and may have been overfit, however

[Multivariate Outlier Detection in High-Dimensional Spectral Data](https://towardsdatascience.com/multivariate-outlier-detection-in-high-dimensional-spectral-data-45878fd0ccb8)

Blog post walking through a couple of methods to detect multivariate outliers. Not sure how helpful this actually is though since all of the authorâ€™s data was in 2d and was working on a basis of â€œremove everything outside of a rangeâ€

Food for thought: you can also create a somewhat looser convex hull by punching out traces from each of the planes normal to each axis. 

We could treat three of the six faces of the RGB cube as our planes and then project the colors down onto each face, allowing for 2d manipulation. Then we could punch out each faceâ€™s traces that exclude the outliers to create another bounding 3D shape."
Play Around with Decompositions,ðŸ¤ž Mostly guessing,"July 1, 2021 10:56 PM","July 1, 2021",1.33 hour(s),1.33,80,"Thought through some new strategies and then tried to reconstruct my desktop wallpaper from the layer decompositions.  For some reason, however, setting all of their blend modes to ""add"" or ""addition"" in both Affinity Designer and GIMP didn't combine them properly, leaving a lot of transparency behind (despite what the decomposition software says, which is that there is very little reconstruction error).  Oh well.

![Play%20Around%20with%20Decompositions%20b1bb6c05f2ba4981a61ccef48dcf5d22/before_3.10.32_PM.png](Play%20Around%20with%20Decompositions%20b1bb6c05f2ba4981a61ccef48dcf5d22/before_3.10.32_PM.png)

The original image

![Play%20Around%20with%20Decompositions%20b1bb6c05f2ba4981a61ccef48dcf5d22/additive.png](Play%20Around%20with%20Decompositions%20b1bb6c05f2ba4981a61ccef48dcf5d22/additive.png)

The recomposition.  Notice the lack of saturation (due to transparency and Notion's grey color).

---

Installed GIMP, and should play around with it for a little bit before making a plugin.  Maybe make an affinity designer plugin as well so that I can actually use it?

---

Messaged Yotam about a new method idea, which is to isolate groups of colors that would affect the shape of the convex hull significantly more than they should given quantity/position/other factors and put these colors into another complex hull or simplex.  Then we can deal with these outliers later."
Intern Training Session #3,ðŸ’ª Confident,"July 1, 2021 7:09 PM","July 1, 2021",1.16 hour(s),1.16,70,"Today we went over how to look at an article.  We practiced by assessing an article's methods, conclusion, and other things such as whether or not we thought it was ""well written"".  We did this to get exposure to what is annoying to find in an article so that we don't do it when we're writing our own."
Post-Meeting Thinking,ðŸ¤” Pretty Sure,"June 30, 2021 11:42 PM","June 30, 2021",1.83 hour(s),1.83,110,"Thought about the outliers, downloaded and played around with the interactive software, and sent a couple of questions to Yotam.  Not sure about their quality since I'm tired tho... lots of thinking today.

---

Also spent a good bit of time trying to figure out what the ""mean shift"" algorithm does.  Currently reading a Stanford presentation on it.

---

## Todo

- [ ]  Find a bunch of images that have something that looks like it could be an outlier, and collect them into a folder
- [ ]  Write a python program that implements the algorithm Yotam recommended I try out

    > Given a set of $N$ points $p_i$ and an outlier percentage $\lambda$, run k-means with $k = \frac N {100-\lambda}$, and then compute the convex hull $k$ times, leaving out one cluster each time. Return the smallest convex hull.

- [ ]  Run this program for each image and compare the output convex hull to the hull without the outliers removed."
Meet With Yotam,ðŸ’ª Confident,"June 30, 2021 11:37 PM","June 30, 2021",1.5 hour(s),1.5,90,"We talked about the papers I read over the past week.  It seemed like he appreciated the amount of work I was doing (good!), and didn't say that it was too slow.  We talked about the next step for the project, which is to define what it means to be an outlier and then try to remove it.  Current thinking is as follows:

> *an outlier is a point or small set of points whose removal has a significant effect on the shape of the convex hull and on the sparsity of the decomposition but doesn't have much of an effect on the image or the reconstruction.*

It's still a work in progress and is pretty tough to nail down.  How do I quantify it?

One of his students (Ted) also showed up to the zoom call, so I got to meet him."
Prepare for Meeting,ðŸ¤ž Mostly guessing,"June 30, 2021 11:36 PM","June 30, 2021",1.91 hour(s),1.91,115,Read through my annotations of the papers and think through the types of questions I will ask as well as what I'm going to try to find out.
Read Yotam's RGBXY Paper,ðŸ’ª Confident,"June 30, 2021 12:33 AM","June 29, 2021",3.75 hour(s),3.75,225,"The paper started off relatively simple and easy to follow (especially after the introduction of the convex hull approximation paper), but got really into the weeds during the section that discussed the process.  The hardest part to wrap my head around is that the vertices of the convex hull are only equivalent to the palette colors for a convex hull in three dimensions (RGB).  The 5D convex hull, which was generated to help avoid ""spatial coherence artifacts"" (using only RGB, it's possible that two neighboring pixels have coordinates in terms of different simplices and will have different weights, so will produce ""speckling"" during reconstruction), doesn't have any equivalents in this way.

I also reached out to Yotam to ask about generalized barycentric coordinates.  If there is more than one simplex and each point has weights in terms of the simplex that contains it (since the simplices are non-overlapping), how do we know which simplex a point belongs to"
Intern Training Session #2,ðŸ’ª Confident,"June 29, 2021 8:04 PM","June 29, 2021",1.25 hour(s),1.25,75,Today we learned about documentation in science.
Set Up Automatic Session Log Generation,ðŸ¤” Pretty Sure,"June 29, 2021 8:03 PM","June 29, 2021",1 hour(s),1,60,"I got bored and set up a system that, when double clicked, will create and open a file for me to take notes in during the twice-a-week ASSIP intern training sessions."
React to ASSIP Lady's Email,ðŸ¤” Pretty Sure,"June 29, 2021 5:44 AM","June 28, 2021",0.75 hour(s),0.75,45,"Dr. Cobb sent out an email that had all sorts of info on how to take notes for a *bio lab*, but nothing on what to do for any of the other types of labs such as mathematics and computer science (the ones that are relevant to me).  I read the 20-page document by the NIH on taking notes, hoping to find something about protecting IP what would be more general and apply outside of bio, but didn't really find anything."
Read New Paper,ðŸ’ª Confident,"June 28, 2021 8:44 PM","June 28, 2021",1.66 hour(s),1.66,100,"Read the first couple pages of the new paper. Itâ€™s really math-heavy and has a lot of set algebra, which I never learned in school (but had slowly been building up on my own through exposure to algorithms in Wikipedia). Thankfully the article had a terminology section :) 

Wrapping my head around some of these definitions is a little tricky, but Iâ€™m getting there. Havenâ€™t made it to the algorithm section yet; still working through the terms and general process. 

---

Edit 1: just finished reading through the paper.  The ideas it had made sense, but wrapping my head around all the set stuff was a lot.  They ended up doing an optimization that tried to minimax a system, so their solution actually made a lot of sense to me (it's similar to alpha-beta pruning)."
Update Yotam again,ðŸ¤” Pretty Sure,"June 26, 2021 12:47 AM","June 25, 2021",1.08 hour(s),1.08,65,Asked more of the questions from my continued annotation. Also asked a question to make sure that I was understanding where our research was going and why.
Read through the Mathy Sections,ðŸ¤” Pretty Sure,"June 25, 2021 7:26 PM","June 25, 2021",2.16 hour(s),2.16,130,"Begin reading sections 3, 4, and 5. They are more detailed and have a lot of mathy syntax, but the ideas presented spiral from the introduction and other parts of the paper so there isnâ€™t much new aside from implementation. 

The paper repeats itself quite a lot, so this has been going pretty fast. The only things that were introduced were how the qualitative attributes the researchers were assessing were going to become quantified."
Update Yotam,ðŸ’ª Confident,"June 25, 2021 5:02 AM","June 24, 2021",2.83 hour(s),2.83,170,"Reread my annotations and tried to answer as many of the questions I asked as I could before asking Yotam.  I also looked a little bit deeper into the specifics of some of the vocabulary (notably the mean value coordinate system), and then got sidetracked by flipping through a Princeton CS lecture on splines.

Additionally, I came up with an interesting idea for reducing reconstruction error that I intend to pass by Yotam for feasability.  It involves projecting the barycentric or mean value coordinates into negatives to include points that lie outside of a polyhedron in RGB space and then finding offsets in the other coordinates that would have equivalent change as a negative color (ie negative grey would get farther from grey, approaching either white or black depending on the axis alignment).

---

**update**

[before mome ripped it](https://www.notion.so/before-mome-ripped-it-a6896a74637746e0b447c17fb9ba46ef)

Thanks for helping me get started!  I spent some time with the paper you suggested.  I skimmed through the whole thing and made it about halfway through annotating a printed copy.  Annotating (marking stuff up) helps me wrap my head around key concepts and definitions (such as what a ""simplex"" is and how it can be used to define points in space).  

I had a few jargon questions as I went along, but was able to work through most of them with some quick google searches.  For example, I learned what ""sparse"" means in a graphics context (turns out sparsity can be helpful since multiplication by zero is easy).  I also learned what a ""barycentric coordinate system"" is and why it (or at least one that uses weights like the proposed mean value coordinates) would be helpful in the decomposition of an image by color.  And I learned the difference between a polyhedron and a convex hull (the latter is a subset of the former).  So, if it sounds like I have this reasonably straight, I think I'm mostly good for now on jargon. 

As for the concepts, I think I have been able to follow them well so far (though I haven't dug in on the math-heavy section yet).  I think that the main idea of their proposal is this: the polyhedron used to determine the weights and the color palette should try to *both* enclose as many colors as possible *and* keep its vertices as close to colors present in the images as possible.  This second part is what differentiates the polyhedron from a convex hull and, in theory, should make for a more representative palette.  Additionally, by using mean value coordinates of degree equal to the number of vertices of the polyhedron (instead of degree 3 used in some other approaches, which is the same as a barycentric system), the polyhedron can be calculated much faster, as it doesn't need to generate and tesselate a lot of simplices.  Please let me know if it seems like I'm missing something here.

Now for some questions/ideas:

First, on page 3, the paper states: ""The ASAP approach is rather fast, however, since the generated layer opacities have only C0 continuity, it suffers from speckling artifacts.""  What does ""continuity"" mean in this context?  Is it referring to the continuity of a two variable function that takes (x, y) and outputs opacity (making a 3D surface)?  What role does continuity play in palette-based decomposition?

Second, while I was reading through the Wikipedia page for barycentric coordinates, I noticed that they can represent a point that lies *outside* of the bounding shape by making one or more of the weights negative.  Normally a point with a negative weight would be discarded since it can't be directly translated to RGB.  However, if another combination of the palette colors could be used to create a similar color using all positive weights instead of a mix of positive and negative weights, then could the point representing this similar color be used to help reduce the increase in reconstruction error introduced by the fact that some points are discarded?  Does this seem like an accurate and useful concept?  If so, are there any papers discussing this type of color conversion?  Or is there only one combination of the palette colors that can reasonably create any other color found in the image?"
Print More Papers,ðŸ¤” Pretty Sure,"June 24, 2021 10:59 PM","June 24, 2021",0.25 hour(s),0.25,15,Print out the two main papers that form the backbone of the one Yotam sent.  They are the RGB color decomposition papers that were co-authored by him.  I labeled them with the way they were cited in the first paper.
Read the Paper Yotam Sent,ðŸ¤” Pretty Sure,"June 24, 2021 8:39 PM","June 24, 2021",2.66 hour(s),2.66,160,"Read and annotated the paper Yotam told me to read.  Current task for the day.  Future step would probably be to print out his papers that were referenced in this one (done) and read them like this too, or at least try to wrap my head around the different color decomposition methods (ASAP RGB, RGBXY, etc).

After about 2.5 hours I am only halfway through the reading and annotating.  I have had to look up many terms and ideas on google and spent a good amount of time on Wikipedia (which is surprisingly helpful for math and computer science).  Currently, I'm taking a break as I transition from the intro/lit review to the meat of the paper where they drill down their proposed process."
Add Resources to Notion Page,ðŸ¤ž Mostly guessing,"June 24, 2021 5:41 PM","June 24, 2021",0.66 hour(s),0.66,40,"Reorganized the quick links so that they're a database and also added a resources page.  The resources page will have links to things that I find helpful as I google to understand parts of papers, such as the definitions of different color spaces.

Also spent way too much time figuring out how to open the link to Yotam's discord in the app instead of the browser and then how to close the browser tab that the redirection website I ended up using would leave open."
Create Notion Page,ðŸ’ª Confident,"June 23, 2021 9:00 PM","June 23, 2021",0.91 hour(s),0.91,55,Create the Notion page for ASSIP.  It currently just has a database to keep track of my time and how I spend it.  The goal is to emulate a 30-hour work week (which won't happen this week since I don't have a project yet).
Think Through Project Ideas,ðŸ’ª Confident,"June 23, 2021 8:48 PM","June 23, 2021",3 hour(s),3,180,"Thought through the variety of project ideas Yotam circulated at our meeting yesterday and decided which were the most interesting.  For each of them, I summarized what the project would be, explained why the project appealed to me, and did some preliminary research.  Then, I sent this list to Yotam through Discord."
Entry,,"June 23, 2021 8:38 PM",,0 hour(s),0,0
